{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "Suppose that we have a fairly new application being developed. This new app is simply a mobile application that tracks the all of the users activity such as browsing and shopping activity.\n",
    "\n",
    "The app development team has asked you to take some data from the app and extract some meaning from it. They were also interested in trying to possibly predict user behavior based on the usage data in the data they provided. For any given user, they want to see if they can use a snapshot of what that person has done at this particular time and predict what they are doing.\n",
    "\n",
    "\n",
    "\n",
    "In this notebook, we would like to see how you would approach solving this problem. The data is provided in the `data` directory as `train.csv` and `test.csv`, so do what you will with this dataset to address the request of the app development team. Good luck and have fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# feel free to add any additional packages you feel you may need\n",
    "#from sklearn import ...\n",
    "#import tensorflow as tf ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION\n",
    "\n",
    "- What are some considerations for the nature of the dataset that you can initially explore?\n",
    "- Can you show what you would like to explore regarding the dataset as presented?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will first see the how my data looks like using .head().I found a column mentionaing the ID and 561 features. In the later part, 'activity. I'm taking it as a classifier target variable.'I found that Then I checked for the nulls values . I did  not found single null value. This is a good sign. Using the .dtypes , I checked the columns datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_553</th>\n",
       "      <th>feature_554</th>\n",
       "      <th>feature_555</th>\n",
       "      <th>feature_556</th>\n",
       "      <th>feature_557</th>\n",
       "      <th>feature_558</th>\n",
       "      <th>feature_559</th>\n",
       "      <th>feature_560</th>\n",
       "      <th>feature_561</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3368.0</td>\n",
       "      <td>0.283100</td>\n",
       "      <td>-0.025501</td>\n",
       "      <td>-0.111181</td>\n",
       "      <td>-0.374477</td>\n",
       "      <td>-0.099568</td>\n",
       "      <td>-0.202966</td>\n",
       "      <td>-0.376311</td>\n",
       "      <td>-0.150160</td>\n",
       "      <td>-0.181695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515315</td>\n",
       "      <td>0.274885</td>\n",
       "      <td>-0.219945</td>\n",
       "      <td>0.670243</td>\n",
       "      <td>0.889311</td>\n",
       "      <td>0.463634</td>\n",
       "      <td>-0.759790</td>\n",
       "      <td>0.140485</td>\n",
       "      <td>0.185921</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3369.0</td>\n",
       "      <td>0.207268</td>\n",
       "      <td>-0.016957</td>\n",
       "      <td>-0.093808</td>\n",
       "      <td>-0.325015</td>\n",
       "      <td>-0.123625</td>\n",
       "      <td>-0.216765</td>\n",
       "      <td>-0.332536</td>\n",
       "      <td>-0.174165</td>\n",
       "      <td>-0.203505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361673</td>\n",
       "      <td>0.016422</td>\n",
       "      <td>0.944645</td>\n",
       "      <td>0.602126</td>\n",
       "      <td>0.807218</td>\n",
       "      <td>-0.111752</td>\n",
       "      <td>-0.761524</td>\n",
       "      <td>0.142055</td>\n",
       "      <td>0.184160</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3370.0</td>\n",
       "      <td>0.204876</td>\n",
       "      <td>-0.015669</td>\n",
       "      <td>-0.090056</td>\n",
       "      <td>-0.335084</td>\n",
       "      <td>-0.097665</td>\n",
       "      <td>-0.219217</td>\n",
       "      <td>-0.344267</td>\n",
       "      <td>-0.148851</td>\n",
       "      <td>-0.198500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.649758</td>\n",
       "      <td>0.524121</td>\n",
       "      <td>0.916242</td>\n",
       "      <td>0.195366</td>\n",
       "      <td>0.811747</td>\n",
       "      <td>-0.261836</td>\n",
       "      <td>-0.759405</td>\n",
       "      <td>0.141793</td>\n",
       "      <td>0.185818</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3371.0</td>\n",
       "      <td>0.240694</td>\n",
       "      <td>-0.031415</td>\n",
       "      <td>-0.106110</td>\n",
       "      <td>-0.326436</td>\n",
       "      <td>-0.066271</td>\n",
       "      <td>-0.198563</td>\n",
       "      <td>-0.332613</td>\n",
       "      <td>-0.105966</td>\n",
       "      <td>-0.166404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363503</td>\n",
       "      <td>0.149105</td>\n",
       "      <td>0.468444</td>\n",
       "      <td>-0.685859</td>\n",
       "      <td>0.431864</td>\n",
       "      <td>-0.366446</td>\n",
       "      <td>-0.757073</td>\n",
       "      <td>0.142311</td>\n",
       "      <td>0.187396</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3372.0</td>\n",
       "      <td>0.270451</td>\n",
       "      <td>-0.013930</td>\n",
       "      <td>-0.100331</td>\n",
       "      <td>-0.309422</td>\n",
       "      <td>-0.017289</td>\n",
       "      <td>-0.160874</td>\n",
       "      <td>-0.314171</td>\n",
       "      <td>-0.052547</td>\n",
       "      <td>-0.117058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257787</td>\n",
       "      <td>-0.081213</td>\n",
       "      <td>0.440825</td>\n",
       "      <td>-0.794300</td>\n",
       "      <td>0.708809</td>\n",
       "      <td>-0.169292</td>\n",
       "      <td>-0.749242</td>\n",
       "      <td>0.145072</td>\n",
       "      <td>0.192380</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0  3368.0   0.283100  -0.025501  -0.111181  -0.374477  -0.099568  -0.202966   \n",
       "1  3369.0   0.207268  -0.016957  -0.093808  -0.325015  -0.123625  -0.216765   \n",
       "2  3370.0   0.204876  -0.015669  -0.090056  -0.335084  -0.097665  -0.219217   \n",
       "3  3371.0   0.240694  -0.031415  -0.106110  -0.326436  -0.066271  -0.198563   \n",
       "4  3372.0   0.270451  -0.013930  -0.100331  -0.309422  -0.017289  -0.160874   \n",
       "\n",
       "   feature_7  feature_8  feature_9  ...  feature_553  feature_554  \\\n",
       "0  -0.376311  -0.150160  -0.181695  ...     0.515315     0.274885   \n",
       "1  -0.332536  -0.174165  -0.203505  ...     0.361673     0.016422   \n",
       "2  -0.344267  -0.148851  -0.198500  ...     0.649758     0.524121   \n",
       "3  -0.332613  -0.105966  -0.166404  ...     0.363503     0.149105   \n",
       "4  -0.314171  -0.052547  -0.117058  ...     0.257787    -0.081213   \n",
       "\n",
       "   feature_555  feature_556  feature_557  feature_558  feature_559  \\\n",
       "0    -0.219945     0.670243     0.889311     0.463634    -0.759790   \n",
       "1     0.944645     0.602126     0.807218    -0.111752    -0.761524   \n",
       "2     0.916242     0.195366     0.811747    -0.261836    -0.759405   \n",
       "3     0.468444    -0.685859     0.431864    -0.366446    -0.757073   \n",
       "4     0.440825    -0.794300     0.708809    -0.169292    -0.749242   \n",
       "\n",
       "   feature_560  feature_561  activity  \n",
       "0     0.140485     0.185921       1.0  \n",
       "1     0.142055     0.184160       1.0  \n",
       "2     0.141793     0.185818       1.0  \n",
       "3     0.142311     0.187396       1.0  \n",
       "4     0.145072     0.192380       1.0  \n",
       "\n",
       "[5 rows x 563 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_552</th>\n",
       "      <th>feature_553</th>\n",
       "      <th>feature_554</th>\n",
       "      <th>feature_555</th>\n",
       "      <th>feature_556</th>\n",
       "      <th>feature_557</th>\n",
       "      <th>feature_558</th>\n",
       "      <th>feature_559</th>\n",
       "      <th>feature_560</th>\n",
       "      <th>feature_561</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.288585</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.913526</td>\n",
       "      <td>-0.995112</td>\n",
       "      <td>-0.983185</td>\n",
       "      <td>-0.923527</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074323</td>\n",
       "      <td>-0.298676</td>\n",
       "      <td>-0.710304</td>\n",
       "      <td>-0.112754</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>-0.464761</td>\n",
       "      <td>-0.018446</td>\n",
       "      <td>-0.841247</td>\n",
       "      <td>0.179941</td>\n",
       "      <td>-0.058627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.278419</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>-0.123520</td>\n",
       "      <td>-0.998245</td>\n",
       "      <td>-0.975300</td>\n",
       "      <td>-0.960322</td>\n",
       "      <td>-0.998807</td>\n",
       "      <td>-0.974914</td>\n",
       "      <td>-0.957686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158075</td>\n",
       "      <td>-0.595051</td>\n",
       "      <td>-0.861499</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>-0.844788</td>\n",
       "      <td>0.180289</td>\n",
       "      <td>-0.054317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.279653</td>\n",
       "      <td>-0.019467</td>\n",
       "      <td>-0.113462</td>\n",
       "      <td>-0.995380</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>-0.978944</td>\n",
       "      <td>-0.996520</td>\n",
       "      <td>-0.963668</td>\n",
       "      <td>-0.977469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414503</td>\n",
       "      <td>-0.390748</td>\n",
       "      <td>-0.760104</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.848933</td>\n",
       "      <td>0.180637</td>\n",
       "      <td>-0.049118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.279174</td>\n",
       "      <td>-0.026201</td>\n",
       "      <td>-0.123283</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.983403</td>\n",
       "      <td>-0.990675</td>\n",
       "      <td>-0.997099</td>\n",
       "      <td>-0.982750</td>\n",
       "      <td>-0.989302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404573</td>\n",
       "      <td>-0.117290</td>\n",
       "      <td>-0.482845</td>\n",
       "      <td>-0.036788</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.848649</td>\n",
       "      <td>0.181935</td>\n",
       "      <td>-0.047663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.276629</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>-0.998139</td>\n",
       "      <td>-0.980817</td>\n",
       "      <td>-0.990482</td>\n",
       "      <td>-0.998321</td>\n",
       "      <td>-0.979672</td>\n",
       "      <td>-0.990441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087753</td>\n",
       "      <td>-0.351471</td>\n",
       "      <td>-0.699205</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.122542</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.847865</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>-0.043892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0  1.0   0.288585  -0.020294  -0.132905  -0.995279  -0.983111  -0.913526   \n",
       "1  2.0   0.278419  -0.016411  -0.123520  -0.998245  -0.975300  -0.960322   \n",
       "2  3.0   0.279653  -0.019467  -0.113462  -0.995380  -0.967187  -0.978944   \n",
       "3  4.0   0.279174  -0.026201  -0.123283  -0.996091  -0.983403  -0.990675   \n",
       "4  5.0   0.276629  -0.016570  -0.115362  -0.998139  -0.980817  -0.990482   \n",
       "\n",
       "   feature_7  feature_8  feature_9  ...  feature_552  feature_553  \\\n",
       "0  -0.995112  -0.983185  -0.923527  ...    -0.074323    -0.298676   \n",
       "1  -0.998807  -0.974914  -0.957686  ...     0.158075    -0.595051   \n",
       "2  -0.996520  -0.963668  -0.977469  ...     0.414503    -0.390748   \n",
       "3  -0.997099  -0.982750  -0.989302  ...     0.404573    -0.117290   \n",
       "4  -0.998321  -0.979672  -0.990441  ...     0.087753    -0.351471   \n",
       "\n",
       "   feature_554  feature_555  feature_556  feature_557  feature_558  \\\n",
       "0    -0.710304    -0.112754     0.030400    -0.464761    -0.018446   \n",
       "1    -0.861499     0.053477    -0.007435    -0.732626     0.703511   \n",
       "2    -0.760104    -0.118559     0.177899     0.100699     0.808529   \n",
       "3    -0.482845    -0.036788    -0.012892     0.640011    -0.485366   \n",
       "4    -0.699205     0.123320     0.122542     0.693578    -0.615971   \n",
       "\n",
       "   feature_559  feature_560  feature_561  \n",
       "0    -0.841247     0.179941    -0.058627  \n",
       "1    -0.844788     0.180289    -0.054317  \n",
       "2    -0.848933     0.180637    -0.049118  \n",
       "3    -0.848649     0.181935    -0.047663  \n",
       "4    -0.847865     0.185151    -0.043892  \n",
       "\n",
       "[5 rows x 562 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID             0\n",
      "feature_1      0\n",
      "feature_2      0\n",
      "feature_3      0\n",
      "feature_4      0\n",
      "feature_5      0\n",
      "feature_6      0\n",
      "feature_7      0\n",
      "feature_8      0\n",
      "feature_9      0\n",
      "feature_10     0\n",
      "feature_11     0\n",
      "feature_12     0\n",
      "feature_13     0\n",
      "feature_14     0\n",
      "feature_15     0\n",
      "feature_16     0\n",
      "feature_17     0\n",
      "feature_18     0\n",
      "feature_19     0\n",
      "feature_20     0\n",
      "feature_21     0\n",
      "feature_22     0\n",
      "feature_23     0\n",
      "feature_24     0\n",
      "feature_25     0\n",
      "feature_26     0\n",
      "feature_27     0\n",
      "feature_28     0\n",
      "feature_29     0\n",
      "              ..\n",
      "feature_533    0\n",
      "feature_534    0\n",
      "feature_535    0\n",
      "feature_536    0\n",
      "feature_537    0\n",
      "feature_538    0\n",
      "feature_539    0\n",
      "feature_540    0\n",
      "feature_541    0\n",
      "feature_542    0\n",
      "feature_543    0\n",
      "feature_544    0\n",
      "feature_545    0\n",
      "feature_546    0\n",
      "feature_547    0\n",
      "feature_548    0\n",
      "feature_549    0\n",
      "feature_550    0\n",
      "feature_551    0\n",
      "feature_552    0\n",
      "feature_553    0\n",
      "feature_554    0\n",
      "feature_555    0\n",
      "feature_556    0\n",
      "feature_557    0\n",
      "feature_558    0\n",
      "feature_559    0\n",
      "feature_560    0\n",
      "feature_561    0\n",
      "activity       0\n",
      "Length: 563, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID             float64\n",
       "feature_1      float64\n",
       "feature_2      float64\n",
       "feature_3      float64\n",
       "feature_4      float64\n",
       "feature_5      float64\n",
       "feature_6      float64\n",
       "feature_7      float64\n",
       "feature_8      float64\n",
       "feature_9      float64\n",
       "feature_10     float64\n",
       "feature_11     float64\n",
       "feature_12     float64\n",
       "feature_13     float64\n",
       "feature_14     float64\n",
       "feature_15     float64\n",
       "feature_16     float64\n",
       "feature_17     float64\n",
       "feature_18     float64\n",
       "feature_19     float64\n",
       "feature_20     float64\n",
       "feature_21     float64\n",
       "feature_22     float64\n",
       "feature_23     float64\n",
       "feature_24     float64\n",
       "feature_25     float64\n",
       "feature_26     float64\n",
       "feature_27     float64\n",
       "feature_28     float64\n",
       "feature_29     float64\n",
       "                ...   \n",
       "feature_533    float64\n",
       "feature_534    float64\n",
       "feature_535    float64\n",
       "feature_536    float64\n",
       "feature_537    float64\n",
       "feature_538    float64\n",
       "feature_539    float64\n",
       "feature_540    float64\n",
       "feature_541    float64\n",
       "feature_542    float64\n",
       "feature_543    float64\n",
       "feature_544    float64\n",
       "feature_545    float64\n",
       "feature_546    float64\n",
       "feature_547    float64\n",
       "feature_548    float64\n",
       "feature_549    float64\n",
       "feature_550    float64\n",
       "feature_551    float64\n",
       "feature_552    float64\n",
       "feature_553    float64\n",
       "feature_554    float64\n",
       "feature_555    float64\n",
       "feature_556    float64\n",
       "feature_557    float64\n",
       "feature_558    float64\n",
       "feature_559    float64\n",
       "feature_560    float64\n",
       "feature_561    float64\n",
       "activity       float64\n",
       "Length: 563, dtype: object"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION\n",
    "\n",
    "- What algorithms would be appropriate for the provided problem and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll apply the various classifiers algorithms with choosing significant features since by using coorelation. Selecting few features on the basis of +ve and -ve coorelation will make our algorithm much faster and will not overfit the data in comparison to selecting all the features.\n",
    "Choices of Algorithms:\n",
    "  \n",
    " **1.Support Vector Machine**\n",
    "  \n",
    " **2.K-Nearest Neighbor**\n",
    "  \n",
    " **3.Decision tree**\n",
    "  \n",
    " **4.Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_105   -0.867392\n",
       "feature_103   -0.861578\n",
       "feature_104   -0.855969\n",
       "feature_368   -0.853138\n",
       "feature_235   -0.850748\n",
       "feature_185   -0.848682\n",
       "feature_367   -0.847063\n",
       "feature_369   -0.842486\n",
       "feature_289   -0.838673\n",
       "feature_290   -0.835074\n",
       "feature_429   -0.832347\n",
       "feature_126   -0.831807\n",
       "feature_448   -0.831683\n",
       "feature_524   -0.829583\n",
       "feature_129   -0.826182\n",
       "feature_288   -0.825200\n",
       "feature_432   -0.824907\n",
       "feature_261   -0.817485\n",
       "feature_550   -0.815461\n",
       "feature_88    -0.814711\n",
       "feature_447   -0.814048\n",
       "feature_273   -0.813195\n",
       "feature_349   -0.811636\n",
       "feature_426   -0.810488\n",
       "feature_101   -0.809882\n",
       "feature_85    -0.809472\n",
       "feature_267   -0.809064\n",
       "feature_435   -0.808374\n",
       "feature_5     -0.808299\n",
       "feature_352   -0.807875\n",
       "                 ...   \n",
       "feature_52     0.552645\n",
       "feature_43     0.556795\n",
       "feature_55     0.557839\n",
       "feature_375    0.561344\n",
       "feature_34     0.586348\n",
       "feature_59     0.598321\n",
       "feature_114    0.599509\n",
       "feature_174    0.602723\n",
       "feature_26     0.603733\n",
       "feature_156    0.622677\n",
       "feature_559    0.626664\n",
       "feature_373    0.632916\n",
       "feature_106    0.633190\n",
       "feature_54     0.643325\n",
       "feature_51     0.646225\n",
       "feature_42     0.646263\n",
       "feature_133    0.653672\n",
       "feature_154    0.665032\n",
       "feature_134    0.680642\n",
       "feature_194    0.698518\n",
       "feature_173    0.730070\n",
       "feature_175    0.742984\n",
       "feature_95     0.744610\n",
       "feature_15     0.751391\n",
       "feature_13     0.757890\n",
       "feature_14     0.773283\n",
       "feature_94     0.784690\n",
       "feature_93     0.786086\n",
       "feature_135    0.791902\n",
       "activity       1.000000\n",
       "Name: activity, Length: 562, dtype: float64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the coorelation \n",
    "train_data[train_data.columns[1:]].corr()['activity'][:].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE\n",
    "#Transforming out train and test data according to our need!\n",
    "train_data1=train_data[['ID','feature_10','feature_103','feature_104','feature_368','feature_235','feature_185'\n",
    "                      ,'feature_367' ,'feature_369','feature_289','feature_290','feature_429','feature_126'\n",
    "                      ,'feature_448','feature_524','feature_129','feature_288','feature_432','feature_261'\n",
    "                      ,'feature_550','feature_88','feature_447','feature_273','feature_349','feature_426'\n",
    "                      ,'feature_101','feature_85','feature_267','feature_435','feature_5','feature_352'\n",
    "                      ,'feature_52','feature_43','feature_55','feature_375','feature_34','feature_59','feature_114'    \n",
    "                      ,'feature_174','feature_26','feature_156','feature_559','feature_373'    \n",
    "                      ,'feature_106','feature_54','feature_51', 'feature_42','feature_133','feature_154',\n",
    "                      'feature_134','feature_194' ,'feature_173','feature_175','feature_95',  \n",
    "                      'feature_15','feature_13' ,'feature_14' ,'feature_94','feature_93',\n",
    "                       'feature_135','activity']]\n",
    "test_data1=test_data[['ID','feature_10','feature_103','feature_104','feature_368','feature_235','feature_185'\n",
    "                      ,'feature_367' ,'feature_369','feature_289','feature_290','feature_429','feature_126'\n",
    "                      ,'feature_448','feature_524','feature_129','feature_288','feature_432','feature_261'\n",
    "                      ,'feature_550','feature_88','feature_447','feature_273','feature_349','feature_426'\n",
    "                      ,'feature_101','feature_85','feature_267','feature_435','feature_5','feature_352'\n",
    "                      ,'feature_52','feature_43','feature_55','feature_375','feature_34','feature_59','feature_114'    \n",
    "                      ,'feature_174','feature_26','feature_156','feature_559','feature_373'    \n",
    "                      ,'feature_106','feature_54','feature_51', 'feature_42','feature_133','feature_154',\n",
    "                      'feature_134','feature_194' ,'feature_173','feature_175','feature_95',  \n",
    "                      'feature_15','feature_13' ,'feature_14' ,'feature_94','feature_93',\n",
    "                       'feature_135']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION\n",
    "\n",
    "- What results can be drawn from your exploration and modelling process?\n",
    "- What is your ultimate choice with regard to final model and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll apply the four algorithms to get the best algorithm on the basis of accuracy of the algorithms! Choosing few features out of 562 features is far better as it will be good for space time tradeoff and will deliver the result.\n",
    "\n",
    "I'll be selecting the model on the basis of accuracy of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "predictors=train_data1.drop(['ID','activity'],axis=1)\n",
    "target=train_data1['activity']\n",
    "x_train,x_cv,y_train,y_cv=train_test_split(predictors,target,test_size=0.27,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.58\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_cv)\n",
    "acc_knn = round(accuracy_score(y_pred,y_cv) * 100, 2)\n",
    "print(acc_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.16\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "svc.fit(x_train, y_train)\n",
    "y_pred = svc.predict(x_cv)\n",
    "acc_svc = round(accuracy_score(y_pred, y_cv) * 100, 2)\n",
    "print(acc_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.51\n"
     ]
    }
   ],
   "source": [
    "#NaiveBaiyes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb=GaussianNB()\n",
    "nb.fit(x_train, y_train)\n",
    "y_pred = nb.predict(x_cv)\n",
    "acc_nb = round(accuracy_score(y_pred, y_cv) * 100, 2)\n",
    "print(acc_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.37\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc= DecisionTreeClassifier()\n",
    "dtc.fit(x_train,y_train)\n",
    "y_pred = dtc.predict(x_cv)\n",
    "acc_dtc = round(accuracy_score(y_pred, y_cv) * 100, 2)\n",
    "print(acc_dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>96.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>96.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>94.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>73.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Method  Score\n",
       "0            KNN  96.58\n",
       "3  Decision Tree  96.37\n",
       "1            SVM  94.16\n",
       "2     NaiveBayes  73.51"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Method': ['KNN', 'SVM', \n",
    "              'NaiveBayes', 'Decision Tree'],\n",
    "    'Score': [acc_knn, acc_svc, \n",
    "              acc_nb, acc_dtc]})\n",
    "models.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION\n",
    "\n",
    "- How would you deploy the chosen algorithm? What were your considerations in making this decision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be using KNN and will check accuracy rate at various values of parameter! I'm using KNN as it has good accuracy rate test at vaiorus split in previous cells.It was almost same for KNN and Decision Tree but KNN is just slightly ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code\n",
    "from sklearn.model_selection import cross_val_score\n",
    "myList=list(range(1,50))\n",
    "\n",
    "# subsetting just the odd ones\n",
    "neighbors = filter(lambda x: x % 2 != 0, myList)\n",
    "\n",
    "# empty list that will hold cv scores\n",
    "cv_scores = []\n",
    "\n",
    "# perform 10-fold cross validation\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, x_train, y_train, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Checking for the best K.\n",
    "index=list(range(1,50,2))\n",
    "# changing to misclassification error\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "# plot misclassification error vs k\n",
    "plt.plot(index, MSE)\n",
    "plt.xlabel('Number of Neighbors K')\n",
    "plt.ylabel('Misclassification Error')\n",
    "plt.show()\n",
    "#Selecting K=3 as it has lowest error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 5. 5. ... 6. 6. 6.]\n"
     ]
    }
   ],
   "source": [
    "#Applying KNN to the test set!\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(test_data1.drop('ID',axis=1))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION\n",
    "\n",
    "- What are your overall conclusions to the problem? What have you made available and how can we use what was built?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have just predicted the activity of test dataset by using our KNN model.\n",
    "Conclusions:\n",
    "\n",
    "  1.We can predict the activity of user by just having few significant features as it is provinding a good accuracy      rate.\n",
    "  \n",
    "  2.KNN model with clusters of 3 seems suitable to solve this problem as it is having lowest Misclassification Error\n",
    "  \n",
    " **Availability**\n",
    " \n",
    " Now I'm creating a separate CSV which will be having the data of test_data and an addition column of 'activiy'        which we have just predicted. \n",
    " \n",
    " **Usability**\n",
    " \n",
    " You can use this model to predict the user activity on the basis of their features\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['activity'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "inaldf = pd.DataFrame(test_data)\n",
    "inaldf.to_csv('predictions.csv', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_553</th>\n",
       "      <th>feature_554</th>\n",
       "      <th>feature_555</th>\n",
       "      <th>feature_556</th>\n",
       "      <th>feature_557</th>\n",
       "      <th>feature_558</th>\n",
       "      <th>feature_559</th>\n",
       "      <th>feature_560</th>\n",
       "      <th>feature_561</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.288585</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.913526</td>\n",
       "      <td>-0.995112</td>\n",
       "      <td>-0.983185</td>\n",
       "      <td>-0.923527</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.298676</td>\n",
       "      <td>-0.710304</td>\n",
       "      <td>-0.112754</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>-0.464761</td>\n",
       "      <td>-0.018446</td>\n",
       "      <td>-0.841247</td>\n",
       "      <td>0.179941</td>\n",
       "      <td>-0.058627</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.278419</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>-0.123520</td>\n",
       "      <td>-0.998245</td>\n",
       "      <td>-0.975300</td>\n",
       "      <td>-0.960322</td>\n",
       "      <td>-0.998807</td>\n",
       "      <td>-0.974914</td>\n",
       "      <td>-0.957686</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.595051</td>\n",
       "      <td>-0.861499</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>-0.844788</td>\n",
       "      <td>0.180289</td>\n",
       "      <td>-0.054317</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.279653</td>\n",
       "      <td>-0.019467</td>\n",
       "      <td>-0.113462</td>\n",
       "      <td>-0.995380</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>-0.978944</td>\n",
       "      <td>-0.996520</td>\n",
       "      <td>-0.963668</td>\n",
       "      <td>-0.977469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.390748</td>\n",
       "      <td>-0.760104</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.848933</td>\n",
       "      <td>0.180637</td>\n",
       "      <td>-0.049118</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.279174</td>\n",
       "      <td>-0.026201</td>\n",
       "      <td>-0.123283</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.983403</td>\n",
       "      <td>-0.990675</td>\n",
       "      <td>-0.997099</td>\n",
       "      <td>-0.982750</td>\n",
       "      <td>-0.989302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117290</td>\n",
       "      <td>-0.482845</td>\n",
       "      <td>-0.036788</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.848649</td>\n",
       "      <td>0.181935</td>\n",
       "      <td>-0.047663</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.276629</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>-0.998139</td>\n",
       "      <td>-0.980817</td>\n",
       "      <td>-0.990482</td>\n",
       "      <td>-0.998321</td>\n",
       "      <td>-0.979672</td>\n",
       "      <td>-0.990441</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.351471</td>\n",
       "      <td>-0.699205</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.122542</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.847865</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>-0.043892</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0  1.0   0.288585  -0.020294  -0.132905  -0.995279  -0.983111  -0.913526   \n",
       "1  2.0   0.278419  -0.016411  -0.123520  -0.998245  -0.975300  -0.960322   \n",
       "2  3.0   0.279653  -0.019467  -0.113462  -0.995380  -0.967187  -0.978944   \n",
       "3  4.0   0.279174  -0.026201  -0.123283  -0.996091  -0.983403  -0.990675   \n",
       "4  5.0   0.276629  -0.016570  -0.115362  -0.998139  -0.980817  -0.990482   \n",
       "\n",
       "   feature_7  feature_8  feature_9  ...  feature_553  feature_554  \\\n",
       "0  -0.995112  -0.983185  -0.923527  ...    -0.298676    -0.710304   \n",
       "1  -0.998807  -0.974914  -0.957686  ...    -0.595051    -0.861499   \n",
       "2  -0.996520  -0.963668  -0.977469  ...    -0.390748    -0.760104   \n",
       "3  -0.997099  -0.982750  -0.989302  ...    -0.117290    -0.482845   \n",
       "4  -0.998321  -0.979672  -0.990441  ...    -0.351471    -0.699205   \n",
       "\n",
       "   feature_555  feature_556  feature_557  feature_558  feature_559  \\\n",
       "0    -0.112754     0.030400    -0.464761    -0.018446    -0.841247   \n",
       "1     0.053477    -0.007435    -0.732626     0.703511    -0.844788   \n",
       "2    -0.118559     0.177899     0.100699     0.808529    -0.848933   \n",
       "3    -0.036788    -0.012892     0.640011    -0.485366    -0.848649   \n",
       "4     0.123320     0.122542     0.693578    -0.615971    -0.847865   \n",
       "\n",
       "   feature_560  feature_561  activity  \n",
       "0     0.179941    -0.058627       5.0  \n",
       "1     0.180289    -0.054317       5.0  \n",
       "2     0.180637    -0.049118       5.0  \n",
       "3     0.181935    -0.047663       5.0  \n",
       "4     0.185151    -0.043892       5.0  \n",
       "\n",
       "[5 rows x 563 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
